# ğŸš€ FirstLangchainWork  

This repository demonstrates **LangChain** integration with **Google Gemini** and **Hugging Face**, utilizing **FAISS** for vector search and **LLM-powered chat models**. The project enables querying via **remote API-based models** and **locally downloaded models** from Hugging Face.  

---

## ğŸ“Œ Features  
- **ğŸ”— LangChain Integration** â€“ Seamlessly connects to LLMs.  
- **ğŸ¤– Google Gemini LLM** â€“ Utilizes `models/embedding-001` for embeddings.  
- **ğŸ“š Hugging Face Chat Model** â€“ Supports both API-based remote models and locally downloaded models.  
- **âš¡ FAISS Vector Store** â€“ Efficient similarity search implementation.  
- **ğŸ“ Query Processing** â€“ Computes cosine similarity for best responses.  

---

## ğŸ“‚ Project Structure  
FirstLangchainWork/
â”‚â”€â”€ venv/                     # Virtual environment (not tracked in Git)
â”‚â”€â”€ .gitignore                 # Ignores venv and .env files
â”‚â”€â”€ .env                       # Environment variables (DO NOT COMMIT)
â”‚â”€â”€ main.py                    # Main script
â”‚â”€â”€ requirements.txt            # Dependencies
â”‚â”€â”€ README.md                   # Project documentation

##Create and Activate Virtual Environment
# Windows  
python -m venv venv  
venv\Scripts\activate  

# macOS/Linux  
python3 -m venv venv  
source venv/bin/activate 

##  Install Dependencies
pip install -r requirements.txt

##Set Up Environment Variables
GOOGLE_API_KEY=your_google_api_key_here
HUGGINGFACE_API_KEY=your_huggingface_api_key_here

## Usage
from langchain.chat_models import ChatHuggingFace
chat_model = ChatHuggingFace(model_name="TinyLlama/TinyLlama-1.1B-Chat-v1.0", api_key="your_huggingface_api_key_here")

###Run the script:
python main.py
